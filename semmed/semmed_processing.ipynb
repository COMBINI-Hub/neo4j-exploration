{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column headers\n",
    "predication_headers = [\n",
    "    'PREDICATION_ID', 'SENTENCE_ID', 'PMID', 'PREDICATE', 'SUBJECT_CUI',\n",
    "    'SUBJECT_NAME', 'SUBJECT_SEMTYPE', 'SUBJECT_NOVELTY', 'OBJECT_CUI',\n",
    "    'OBJECT_NAME', 'OBJECT_SEMTYPE', 'OBJECT_NOVELTY', 'FACT_VALUE_CHAR',\n",
    "    'MOD_SCALE_CHAR', 'MOD_VALUE_FLOAT'\n",
    "]\n",
    "\n",
    "predication_aux_headers = [\n",
    "    'PREDICATION_AUX_ID', 'PREDICATION_ID', 'SUBJECT_TEXT', 'SUBJECT_DIST',\n",
    "    'SUBJECT_MAXDIST', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX', 'SUBJECT_SCORE',\n",
    "    'INDICATOR_TYPE', 'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'OBJECT_TEXT',\n",
    "    'OBJECT_DIST', 'OBJECT_MAXDIST', 'OBJECT_START_INDEX', 'OBJECT_END_INDEX',\n",
    "    'OBJECT_SCORE', 'CURR_TIMESTAMP'\n",
    "]\n",
    "\n",
    "# predication_dtype = {\n",
    "#     'PREDICATION_ID': 'int32',\n",
    "#     'SENTENCE_ID': 'int32',\n",
    "#     'PMID': 'str',\n",
    "#     'PREDICATE': 'str',\n",
    "#     'SUBJECT_CUI': 'str',\n",
    "#     'SUBJECT_NAME': 'str',\n",
    "#     'SUBJECT_SEMTYPE': 'str',\n",
    "#     'SUBJECT_NOVELTY': 'int8',\n",
    "#     'OBJECT_CUI': 'str',\n",
    "#     'OBJECT_NAME': 'str',\n",
    "#     'OBJECT_SEMTYPE': 'str',\n",
    "#     'OBJECT_NOVELTY': 'int8',\n",
    "#     'FACT_VALUE_CHAR': 'str',\n",
    "#     'MOD_SCALE_CHAR': 'str',\n",
    "#     'MOD_VALUE_FLOAT': 'float32'\n",
    "# }\n",
    "\n",
    "# predication_aux_dtype = {\n",
    "#     'PREDICATION_AUX_ID': 'int32',\n",
    "#     'PREDICATION_ID': 'int32',\n",
    "#     'SUBJECT_TEXT': 'str',\n",
    "#     'SUBJECT_DIST': 'int32',\n",
    "#     'SUBJECT_MAXDIST': 'int32',\n",
    "#     'SUBJECT_START_INDEX': 'int32',\n",
    "#     'SUBJECT_END_INDEX': 'int32',\n",
    "#     'SUBJECT_SCORE': 'int32',\n",
    "#     'INDICATOR_TYPE': 'str',\n",
    "#     'PREDICATE_START_INDEX': 'int32',\n",
    "#     'PREDICATE_END_INDEX': 'int32',\n",
    "#     'OBJECT_TEXT': 'str',\n",
    "#     'OBJECT_DIST': 'int32',\n",
    "#     'OBJECT_MAXDIST': 'int32',\n",
    "#     'OBJECT_START_INDEX': 'int32',\n",
    "#     'OBJECT_END_INDEX': 'int32',\n",
    "#     'OBJECT_SCORE': 'int32',\n",
    "#     'CURR_TIMESTAMP': 'string'  # Assuming timestamp is read as string\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Nodes\n",
    "The following code will create two CSVs for entity and predication nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file with the specified headers using Dask\n",
    "df = pd.read_csv('semmed_data/predication.csv', names=predication_headers, encoding='ISO-8859-1', on_bad_lines='warn', na_values=['\\\\N'])\n",
    "\n",
    "# Read the CSV file with the specified headers using Dask\n",
    "df_aux = pd.read_csv('semmed_data/predication_aux.csv', names=predication_aux_headers, encoding='ISO-8859-1', on_bad_lines='warn', na_values=['\\\\N']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export both DataFrames to a single .pkl file\n",
    "# dataframes = {'df': df, 'df_aux': df_aux}\n",
    "# dd.to_pickle(dataframes, 'semmed_data/dataframes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge with Dask\n",
    "# merged_df = dd.merge(df, df_aux, on='PREDICATION_ID', how='inner', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_aux, on='PREDICATION_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predication_columns = ['PREDICATION_ID', 'SENTENCE_ID', 'PMID', 'PREDICATE',\n",
    "                      'SUBJECT_CUI', 'OBJECT_CUI', 'INDICATOR_TYPE', \n",
    "                      'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX']\n",
    "\n",
    "predication_df = merged_df[predication_columns].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_columns = ['SUBJECT_CUI', 'SUBJECT_NAME', 'SUBJECT_SEMTYPE', 'SUBJECT_NOVELTY',\n",
    "                  'SUBJECT_TEXT', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', \n",
    "                  'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX', 'SUBJECT_SCORE']\n",
    "\n",
    "# Extract subject entities\n",
    "subject_entities = merged_df[subject_columns].drop_duplicates()\n",
    "\n",
    "# Rename columns to prepare for merging with object entities\n",
    "concept_columns = ['CUI', 'NAME', 'SEMTYPE', 'NOVELTY', 'TEXT', \n",
    "                 'DIST', 'MAXDIST', 'START_INDEX', 'END_INDEX', 'SCORE']\n",
    "\n",
    "subject_entities.columns = concept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract object entities using the same structure\n",
    "object_columns = ['OBJECT_CUI', 'OBJECT_NAME', 'OBJECT_SEMTYPE', 'OBJECT_NOVELTY',\n",
    "                 'OBJECT_TEXT', 'OBJECT_DIST', 'OBJECT_MAXDIST', \n",
    "                 'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE']\n",
    "\n",
    "object_entities = merged_df[object_columns].drop_duplicates()\n",
    "object_entities.columns = concept_columns\n",
    "\n",
    "# Combine subject and object entities and remove duplicates based on CUI\n",
    "concept_df = pd.concat([subject_entities, object_entities]).drop_duplicates(subset=['CUI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predication dataframe shape: {predication_df.shape}\")\n",
    "print(f\"Entity dataframe shape: {concept_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predication_df.to_csv(\"predication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_df.to_csv(\"concept.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Relationships\n",
    "The following code will create a CSV with all the connections between the concepts and predicates in a format that is easily digestible by Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/zxp8f4td2vx7dq5m0kctlj380000gq/T/ipykernel_40231/3743428163.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  predication_df = pd.read_csv(\"predication.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "predication_df = pd.read_csv(\"predication.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe for connections\n",
    "connections_columns = ['src_node', 'dest_node', 'label']\n",
    "connections_df = pd.DataFrame(columns=connections_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Connections between predication instances and subjects (inst_subject)\n",
    "inst_subject_connections = pd.DataFrame({\n",
    "    'src_node': predication_df['PREDICATION_ID'],\n",
    "    'dest_node': predication_df['SUBJECT_CUI'],\n",
    "    'label': 'inst_subject'\n",
    "})\n",
    "\n",
    "# 2. Connections between predication instances and objects (inst_object)\n",
    "inst_object_connections = pd.DataFrame({\n",
    "    'src_node': predication_df['PREDICATION_ID'],\n",
    "    'dest_node': predication_df['OBJECT_CUI'],\n",
    "    'label': 'inst_object'\n",
    "})\n",
    "\n",
    "# 3. Connections between subjects and objects (using PREDICATE as the label)\n",
    "subject_object_connections = pd.DataFrame({\n",
    "    'src_node': predication_df['SUBJECT_CUI'],\n",
    "    'dest_node': predication_df['OBJECT_CUI'],\n",
    "    'label': predication_df['PREDICATE']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all connections into the final connections dataframe\n",
    "connections_df = pd.concat([\n",
    "    inst_subject_connections,\n",
    "    inst_object_connections,\n",
    "    subject_object_connections\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connections dataframe shape: (391440519, 3)\n",
      "   src_node      dest_node         label\n",
      "0  10592604       C0003725  inst_subject\n",
      "1  10592697       C0039258  inst_subject\n",
      "2  10592728       C0318627  inst_subject\n",
      "3  10592759       C0446169  inst_subject\n",
      "4  10592832       C0012634  inst_subject\n",
      "5  10592873       C0042776  inst_subject\n",
      "6  10593057       C0999630  inst_subject\n",
      "7  10593208       C0242210  inst_subject\n",
      "8  10593243  C0056207|3075  inst_subject\n",
      "9  10593287       C0242210  inst_subject\n"
     ]
    }
   ],
   "source": [
    "# Reset the index for the final dataframe\n",
    "connections_df = connections_df.reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Connections dataframe shape: {connections_df.shape}\")\n",
    "print(connections_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_df.to_csv(\"connections.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
